{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.abspath(\"../\")\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "train.csv\n",
      "valid.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(ROOT, \"data/wm811k/baselines/wmfpr/\")\n",
    "print(*os.listdir(DATA_DIR), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.5 s, sys: 92.2 ms, total: 2.59 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"), index_col=0)\n",
    "df_valid = pd.read_csv(os.path.join(DATA_DIR, \"valid.csv\"), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df: pd.DataFrame):\n",
    "    y = df.copy()['label']\n",
    "    X = df.copy().drop('label', axis=1)\n",
    "    X = X.replace([-np.inf, np.inf], np.nan)\n",
    "    X = X.fillna(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X & y\n",
    "X_train, y_train = split_dataframe(df_train)\n",
    "X_valid, y_valid = split_dataframe(df_valid)\n",
    "X_test, y_test = split_dataframe(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center, donut, edge-loc, edge-ring, loc, near-full, none, random, scratch\n"
     ]
    }
   ],
   "source": [
    "# Encode string labels to integers\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train);\n",
    "print(*le.classes_, sep=', ')\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_valid = le.transform(y_valid)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df: pd.DataFrame, scaler):\n",
    "    df_kwargs = dict(index=df.index, columns=df.columns)\n",
    "    return pd.DataFrame(scaler.transform(df.values), **df_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features (X ~ N(0, 1))\n",
    "scl = StandardScaler()\n",
    "scl.fit(X_train);\n",
    "\n",
    "X_train = normalize_dataframe(X_train, scaler=scl)\n",
    "X_valid = normalize_dataframe(X_valid, scaler=scl)\n",
    "X_test = normalize_dataframe(X_test, scaler=scl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_subset(y, p: float):\n",
    "    indices, _ = train_test_split(np.arange(len(y)), train_size=p, stratify=y, random_state=2015010720)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(model, X, y):\n",
    "    from sklearn.metrics import f1_score\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [0.01, 0.05, 0.10, 0.25, 0.50, 1.00]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf_kwargs = dict(n_estimators=100, criterion='gini', max_features='sqrt')\n",
    "param_grid = dict(max_depth=[3, 5, 7, None])\n",
    "\n",
    "for p in P:\n",
    "    \n",
    "    rf = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(**rf_kwargs),\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1_macro',\n",
    "        cv=5,\n",
    "        n_jobs=8,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    if p < 1.00:\n",
    "        indices = get_index_subset(y_train, p=p)\n",
    "        rf.fit(X_train.iloc[indices], y_train[indices])\n",
    "    else:\n",
    "        rf.fit(X_train, y_train)\n",
    "    print(f\"LP={p:.2f}, Test F-1:\", f\"{macro_f1(rf, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gb_kwargs = dict(n_estimators=100, criterion='friedman_mse', learning_rate=1.0, max_depth=None)\n",
    "for p in P:\n",
    "    gb = GradientBoostingClassifier(**gb_kwargs)\n",
    "    if p < 1.00:\n",
    "        indices = get_index_subset(y_train, p=p)\n",
    "        gb.fit(X_train.iloc[indices], y_train[indices])\n",
    "    else:\n",
    "        gb.fit(X_train, y_train)\n",
    "    print(f\"LP={p:.2f}, Test F-1:\", f\"{macro_f1(gb, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm_kwargs = {'C': 1.0, 'dual': False, 'class_weight': 'balanced', 'verbose': 0}\n",
    "for p in P:\n",
    "    lsvm = LinearSVC(**lsvm_kwargs)\n",
    "    if p < 1.00:\n",
    "        indices = get_index_subset(y_train, p=p)\n",
    "        lsvm.fit(X_train.iloc[indices], y_train[indices])\n",
    "    else:\n",
    "        lsvm.fit(X_train, y_train)\n",
    "    print(f\"LP={p:.2f}, Test F-1:\", f\"{macro_f1(lsvm, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP=0.01, Test F-1: 0.5722\n",
      "LP=0.05, Test F-1: 0.6961\n",
      "LP=0.10, Test F-1: 0.7166\n",
      "LP=0.25, Test F-1: 0.7573\n",
      "LP=0.50, Test F-1: 0.7850\n",
      "LP=1.00, Test F-1: 0.8000\n",
      "CPU times: user 11 s, sys: 11.5 s, total: 22.5 s\n",
      "Wall time: 33min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rf_kwargs = dict(n_estimators=100, criterion='gini', max_features='sqrt', max_depth=None)\n",
    "gb_kwargs = dict(n_estimators=100, criterion='friedman_mse', learning_rate=1.0, max_depth=None)\n",
    "lg_kwargs = dict(penalty='l2', dual=False, C=1.0, solver='lbfgs')\n",
    "for p in P:\n",
    "    vt = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(**rf_kwargs)),\n",
    "            ('gb', GradientBoostingClassifier(**gb_kwargs)),\n",
    "            ('lg', LogisticRegression(**lg_kwargs)),\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=[0.767, 0.829, 0.727],\n",
    "        n_jobs=8,\n",
    "    )\n",
    "    if p < 1.00:\n",
    "        indices = get_index_subset(y_train, p=p)\n",
    "        vt.fit(X_train.iloc[indices], y_train[indices])\n",
    "    else:\n",
    "        vt.fit(X_train, y_train)\n",
    "    print(f\"LP={p:.2f}, Test F-1:\", f\"{macro_f1(vt, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lg_kwargs = dict(\n",
    "    Cs=10,  # 10 values in log scale, 1e-4 ~ 1e4.\n",
    "    cv=5,\n",
    "    dual=False,\n",
    "    penalty='l2',\n",
    "    scoring='f1_macro',\n",
    "    solver='sag',\n",
    "    max_iter=100,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=8,\n",
    "    refit=True,\n",
    "    multi_class='multinomial',\n",
    "    verbose=1,\n",
    ")\n",
    "lg = LogisticRegressionCV(**lg_kwargs)\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best C:\", lg.C_)\n",
    "print(\"Test F-1:\", f\"{macro_f1(lg, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test F-1:\", f\"{macro_f1(gb, X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_f1(lsvm, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
